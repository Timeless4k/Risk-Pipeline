{
  "timestamp": "2025-09-11T00:30:03.787983",
  "title": "Causality vs. Correlation: Interpretability Caveats",
  "key_points": [
    "SHAP explains model predictions given the features; it does not establish causal relationships.",
    "Feature importance can be confounded by collinearity, proxy variables, and data leakage.",
    "For causal claims, consider instrumental variables, difference-in-differences, or causal DAGs.",
    "Use out-of-sample tests and regime-conditional stability checks to mitigate spurious relations.",
    "When possible, validate with natural experiments or exogenous shocks."
  ],
  "recommended_methods": [
    "Causal graphs (DAGs) to encode assumptions",
    "Invariant Risk Minimization (IRM) across regimes/markets",
    "Granger causality for temporal predictiveness (not true causality)",
    "Sensitivity analyses to distribution shifts"
  ]
}